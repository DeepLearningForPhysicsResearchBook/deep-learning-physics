{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 12.1 - Solution\n",
    "## Weights and activations of a convolutional network:\n",
    "This task consists of two parts. First, set up and evaluate a\n",
    "convolutional neural network.\n",
    " 1. Set up and train a convolutional network on the classification of images (data set CIFAR-10). Train your network to at least 70% test accuracy.\n",
    "  - Plot the confusion matrix. What do you observe?\n",
    "  - Plot several falsely classified images along with the predicted class scores. What kinds of misclassification do you observe, why do they occur?\n",
    " 2. Plot the filter weights in the first layer of your network and see if you can make any sense of it.\n",
    " 3. Visualize the activations in the first two layers of your network for two input images of choice and describe what you see.\n",
    "  - Does it meet your expectations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "layers = keras.layers\n",
    "print(\"keras\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download CIFAR-10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - 128.) / 128.\n",
    "x_test = (x_test - 128.) / 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design, train, and evaluate a simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 36)        2736      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 36)        11700     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        20800     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 442,478\n",
      "Trainable params: 442,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    layers.Convolution2D(36, kernel_size=(5, 5), padding=\"same\", activation='elu', input_shape=(32, 32, 3)),\n",
    "    layers.Convolution2D(36, kernel_size=(3, 3), padding=\"same\", activation='elu'),\n",
    "    layers.Convolution2D(64, kernel_size=(3, 3), padding=\"same\", strides=(2, 2), activation='elu'),\n",
    "    layers.Convolution2D(64, kernel_size=(3, 3), padding=\"same\", activation='elu'),\n",
    "    layers.Convolution2D(128, kernel_size=(3, 3), padding=\"same\", strides=(2, 2), activation='elu'),\n",
    "    layers.Convolution2D(128, kernel_size=(3, 3), padding=\"same\", activation='elu'),\n",
    "    layers.Convolution2D(128, kernel_size=(3, 3), padding=\"same\", strides=(2, 2), activation='elu'),\n",
    "    layers.GlobalMaxPooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1407/1407 [==============================] - 237s 167ms/step - loss: 1.9317 - accuracy: 0.2949 - val_loss: 1.5764 - val_accuracy: 0.4274\n",
      "Epoch 2/30\n",
      "1407/1407 [==============================] - 223s 159ms/step - loss: 1.6021 - accuracy: 0.4244 - val_loss: 1.4575 - val_accuracy: 0.4660\n",
      "Epoch 3/30\n",
      "1407/1407 [==============================] - 257s 183ms/step - loss: 1.5117 - accuracy: 0.4544 - val_loss: 1.3640 - val_accuracy: 0.5170\n",
      "Epoch 4/30\n",
      "1407/1407 [==============================] - 262s 186ms/step - loss: 1.4359 - accuracy: 0.4849 - val_loss: 1.3732 - val_accuracy: 0.4974\n",
      "Epoch 5/30\n",
      "1407/1407 [==============================] - 261s 186ms/step - loss: 1.3819 - accuracy: 0.4988 - val_loss: 1.3075 - val_accuracy: 0.5140\n",
      "Epoch 6/30\n",
      "1407/1407 [==============================] - 259s 184ms/step - loss: 1.3380 - accuracy: 0.5198 - val_loss: 1.2860 - val_accuracy: 0.5388\n",
      "Epoch 7/30\n",
      "1407/1407 [==============================] - 257s 183ms/step - loss: 1.3001 - accuracy: 0.5345 - val_loss: 1.2507 - val_accuracy: 0.5488\n",
      "Epoch 8/30\n",
      "1407/1407 [==============================] - 266s 189ms/step - loss: 1.2173 - accuracy: 0.5662 - val_loss: 1.1913 - val_accuracy: 0.5656\n",
      "Epoch 9/30\n",
      "1407/1407 [==============================] - 164s 117ms/step - loss: 1.1690 - accuracy: 0.5783 - val_loss: 1.2216 - val_accuracy: 0.5650\n",
      "Epoch 10/30\n",
      "1179/1407 [========================>.....] - ETA: 26s - loss: 1.1107 - accuracy: 0.6018"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train_one_hot,\n",
    "         batch_size=32,\n",
    "         epochs=30,\n",
    "         verbose=1,\n",
    "         validation_split=0.1,\n",
    "         callbacks = [keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5, verbose=1, min_lr=1e-5)],\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, (12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(results.history['accuracy'])\n",
    "plt.plot(results.history['val_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot predictions\n",
    "#### Task\n",
    "Investigate the predictions of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(X, Y, Y_predict, fname=False):\n",
    "    \"\"\"\n",
    "    Plot image X along with predicted probabilities Y_predict.\n",
    "    X: CIFAR image, shape = (32, 32, 3)\n",
    "    Y: CIFAR label, one-hot encoded, shape = (10)\n",
    "    Y_predict: predicted probabilities, shape = (10)\n",
    "    \"\"\"\n",
    "    X = 128 * X + 128\n",
    "    labels = np.array(['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                       'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "    # plot image\n",
    "    ax1.imshow(X.astype('uint8'), origin='upper')\n",
    "    ax1.set(xticks=[], yticks=[])\n",
    "\n",
    "    # plot probabilities\n",
    "    ax2.barh(np.arange(10), Y_predict, align='center')\n",
    "    ax2.set(xlim=(0, 1), xlabel='Score', yticks=[])\n",
    "\n",
    "    for i in range(10):\n",
    "        c = 'red' if (i == np.argmax(Y)) else 'black'\n",
    "        ax2.text(0.05, i, labels[i].capitalize(), ha='left', va='center', color=c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test, verbose=1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(x_test), 1)[0]\n",
    "plot_prediction(x_test[idx], y_test_one_hot[idx], y_pred[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(x_test), 1)[0]\n",
    "plot_prediction(x_test[idx], y_test_one_hot[idx], y_pred[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot confusion matrix\n",
    "#### Task\n",
    "Plot the confusion matrix and comment on your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(Y_true, Y_predict, fname=False):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix\n",
    "    Y_true:    array of true classifications (0-9), shape = (N)\n",
    "    Y_predict: array of predicted classifications (0-9), shape = (N)\n",
    "    \"\"\"\n",
    "    labels = np.array(['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                       'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "    C = np.histogram2d(Y_true, Y_predict, bins=np.linspace(-0.5, 9.5, 11))[0]\n",
    "    Cn = C / np.sum(C, axis=1)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(Cn, interpolation='nearest', vmin=0, vmax=1, cmap=plt.cm.YlGnBu)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('prediction')\n",
    "    plt.ylabel('truth')\n",
    "    plt.xticks(range(10), labels, rotation='vertical')\n",
    "    plt.yticks(range(10), labels)\n",
    "\n",
    "    for x in range(10):\n",
    "\n",
    "        for y in range(10):\n",
    "            plt.annotate('%i' % C[x, y], xy=(y, x), ha='center', va='center')\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_cl = np.argmax(y_pred, axis=1)\n",
    "y_test_cl = np.argmax(y_test_one_hot, axis=1)\n",
    "\n",
    "plot_confusion(y_test_cl, y_predict_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The most misclassifications occur for classes that share similar features in the CNN.\n",
    "Samples of these classes have similar shapes, colors, and structures.\n",
    "Thus, most misclassifications occur e.g., for birds and airplanes or cats and dogs.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot filter weights of the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Plot the filters in the first convolution layer\n",
    "# ----------------------------------------------------------\n",
    "conv1 = model.layers[0]\n",
    "\n",
    "W1, b1 = conv1.get_weights()\n",
    "W1 = (W1 * 128 + 128).astype(np.int)\n",
    "\n",
    "nx, ny, nc, nf = W1.shape\n",
    "n = np.ceil(nf**.5).astype(int)\n",
    "fig, axes = plt.subplots(n, n, figsize=(7, 7))\n",
    "fig.subplots_adjust(left=0.05, bottom=0.05, right=0.95, top=0.95, hspace=0, wspace=0)\n",
    "\n",
    "\n",
    "for i in range(n**2):\n",
    "    ax = axes.flat[i]\n",
    "\n",
    "    if i < nf:\n",
    "        ax.imshow(W1[..., i], origin='upper')\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "    else:\n",
    "        ax.axis('Off')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.suptitle('36 convolutional filters', va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot activations in convolutional layers\n",
    "#### Task\n",
    "Visualize the filters in the first convolutional layer of your CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_activation(A, name='conv'):\n",
    "    nx, ny, nf = A.shape\n",
    "    n = np.ceil(nf**.5).astype(int)\n",
    "    fig, axes = plt.subplots(n, n, figsize=(8, 8))\n",
    "    fig.subplots_adjust(left=0.05, bottom=0.05, right=0.95, top=0.95, hspace=0, wspace=0)\n",
    "\n",
    "    for i in range(n**2):\n",
    "        ax = axes.flat[i]\n",
    "\n",
    "        if i < nf:\n",
    "            ax.imshow(A[..., i], origin='upper', cmap=plt.cm.Greys)\n",
    "            ax.xaxis.set_visible(False)\n",
    "            ax.yaxis.set_visible(False)\n",
    "        else:\n",
    "            ax.axis('Off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle(name, va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task\n",
    "Visualize the activations in the first two layers of your network for two input images of choice and describe what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')  # remove annoying TF warnings\n",
    "\n",
    "idx = np.random.choice(len(x_test), 1)[0]\n",
    "conv_layers = [l for l in model.layers if type(l) == layers.Conv2D]\n",
    "\n",
    "for conv in conv_layers:\n",
    "    conv_model = keras.models.Model(model.inputs, [conv.output])\n",
    "    Xin = x_test[idx][np.newaxis]\n",
    "    Xout1 = conv_model.predict(Xin)[0]\n",
    "    visualize_activation(Xout1, 'image:%i  -  layer: %s' % (idx, conv.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(x_test), 1)[0]\n",
    "\n",
    "for conv in conv_layers:\n",
    "    conv_model = keras.models.Model(model.inputs, [conv.output])\n",
    "    Xin = x_test[idx][np.newaxis]\n",
    "    Xout1 = conv_model.predict(Xin)[0]\n",
    "    visualize_activation(Xout1, 'image:%i  -  layer: %s' % (idx, conv.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Whereas in the first few layers, the working principle of the CNN can be somehow, in a sense, be interpreted as a simple application of image [filters from image processing](https://en.wikipedia.org/wiki/Kernel_(image_processing), this is not possible for deeper layers.\n",
    "To get insights into the working principle of a CNN, more sophistaced methods are needed. Check, e.g., [Exercise 12.2](Exercise_12_2.ipynb).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
